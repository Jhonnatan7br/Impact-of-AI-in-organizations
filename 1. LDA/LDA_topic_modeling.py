#%%
# https://radimrehurek.com/gensim/models/ldamodel.html
#Document: some text.
#Corpus: a collection of documents.
#Vector: a mathematically convenient representation of a document.
#Model: an algorithm for transforming vectors from one representation to another.

import pprint
import pandas as pd
from gensim import corpora, models
from gensim.test.utils import common_texts
from gensim.corpora.dictionary import Dictionary
from gensim.models import LdaModel

from nltk.corpus import stopwords
import pyLDAvis.gensim_models as gensimvis
import pyLDAvis
import matplotlib.pyplot as plt

import pyLDAvis.gensim_models as gensimvis
import pyLDAvis

research = pd.read_csv("C:/Users/Jhonnatan/Documents/GitHub/Impact-of-AI-in-organizations/Datasets/scopus.csv")

# Create a sub-dataset with the first 10 lines
sub_dataset = research.head(10)
# Extract descriptions from the 'description' column of the dataframe
text_corpus = sub_dataset['Abstract'].tolist()
text_corpus = [f'"{doc}"' for doc in text_corpus]

# Create a set of frequent words
stoplist = set('for a of the and to in'.split(' '))
# Lowercase each document, split it by white space and filter out stopwords
texts = [[word for word in document.lower().split() if word not in stoplist]
         for document in text_corpus]

# Count word frequencies
from collections import defaultdict
frequency = defaultdict(int)
for text in texts:
    for token in text:
        frequency[token] += 1 # Increase frecuency Token or decrease depending espected results

# Only keep words that appear more than once
processed_corpus = [[token for token in text if frequency[token] > 1] for text in texts]
pprint.pprint(processed_corpus)


# Attempting to directly pass processed_corpus to LdaModel without first converting it to a Bag-of-Words (BoW) format using the doc2bow method for each document

# Create Dictionary for processed corpus
dictionary = corpora.Dictionary(processed_corpus)
print(dictionary)

# Convert the dictionary to a bag-of-words corpus for reference.
corpus = [dictionary.doc2bow(text) for text in processed_corpus]

""" Train an LDA model using a Gensim corpus """
# Create a corpus from a list of texts
common_dictionary = Dictionary(common_texts)
common_corpus = [common_dictionary.doc2bow(text) for text in common_texts]
# Train the LDA model on the BoW corpus.
#lda = LdaModel(corpus, num_topics=10)
# Train the LDA model
lda_model = LdaModel(corpus, num_topics=10, id2word=dictionary, passes=15)
#lda = models.LdaModel(corpus, num_topics=10)


# Create a visualization
vis_data = gensimvis.prepare(lda_model, corpus, dictionary)
pyLDAvis.display(vis_data)

"""I understand that you are facing issues with your LDA model, where it is interpreting grammatical connectors as topics. This is a common problem in topic modeling, and there are several strategies that you can use to address it. Here are some suggestions:

1. **Stopword removal**: Remove common words such as "and", "the", "is", "with", etc. from the documents before training the LDA model. This can be done using libraries such as NLTK or spaCy.

2. **Part-of-speech (POS) filtering**: Filter out words based on their part-of-speech tags. For example, you can remove all words that are tagged as determiners, conjunctions, prepositions, etc. This can be done using libraries such as spaCy.

3. **Topic coherence**: Use topic coherence measures to evaluate the quality of the topics generated by the LDA model. Topic coherence measures such as UMass, UCI, and CV can help you identify the most coherent topics.

4. **Hyperparameter tuning**: Experiment with different hyperparameters such as alpha, eta, and the number of topics to find the best configuration for your LDA model.

5. **Custom stopwords**: Create a custom list of stopwords that are specific to your domain. For example, if you are working with medical documents, you can create a list of medical stopwords that are not present in the standard stopword list.

I hope these strategies help you extract the topics and concepts that matter. Let me know if you have any other questions or concerns.

Source: Conversation with Bing, 26/1/2024
(1) Ultimate Guide to Linear Discriminant Analysis (LDA). https://dataaspirant.com/linear-discriminant-analysis/.
(2) Linear Discriminant Analysis For Quantitative Portfolio Management. https://blog.quantinsti.com/linear-discriminant-analysis-quantitative-portfolio-management/.
(3) Latent Dirichlet allocation (LDA) and topic modeling: models .... https://link.springer.com/article/10.1007/s11042-018-6894-4."""

#%%
"""
from flask import Flask, render_template

app = Flask(__name__)

@app.route('/')
def display_lda():
    return render_template('LDA_interface.html', vis_data=vis_data)

if __name__ == '__main__':
    app.run(debug=True)
"""